"""ç³»ç»Ÿè¿ç»´é¢æ¿ï¼šæ‰‹åŠ¨æ§åˆ¶åç«¯å„é¡¹åå°æµç¨‹ã€‚"""
from __future__ import annotations

import os
from typing import Any, Dict, Optional

import pandas as pd
import requests
import streamlit as st


@st.cache_data(show_spinner=False)
def _get_backend_base_url() -> str:
    return (
        st.secrets.get("backend_base_url")
        or os.getenv("BACKEND_BASE_URL", "http://localhost:5000")
    ).rstrip("/")


def _get(path: str) -> Dict[str, Any]:
    base_url = _get_backend_base_url()
    try:
        response = requests.get(f"{base_url}{path}", timeout=8)
        response.raise_for_status()
        return response.json()
    except Exception as exc:  # pragma: no cover - å‰ç«¯å®¹é”™
        st.error(f"è·å–çŠ¶æ€å¤±è´¥: {exc}")
        return {}


def _post(path: str, payload: Optional[Dict[str, Any]] = None, *, spinner: str) -> Dict[str, Any]:
    base_url = _get_backend_base_url()
    with st.spinner(spinner):
        try:
            response = requests.post(
                f"{base_url}{path}",
                json=payload,
                timeout=60,
            )
            response.raise_for_status()
            if response.headers.get("Content-Type", "").startswith("application/json") and response.text:
                return response.json()
            return {"message": "æ“ä½œå·²å®Œæˆ"}
        except Exception as exc:  # pragma: no cover - å‰ç«¯å®¹é”™
            st.error(f"æ“ä½œå¤±è´¥: {exc}")
            return {}


def _render_status_panel(status: Dict[str, Any]) -> None:
    st.markdown("### ğŸ“ˆ å½“å‰è¿è¡Œæ€")
    ingestion = status.get("ingestion", {})
    loop_status = status.get("incremental_loop", {})

    col_a, col_b, col_c = st.columns(3)
    with col_a:
        st.metric(
            "æ•°æ®æ‘„å–",
            "è¿è¡Œä¸­" if ingestion.get("running") else "å·²åœæ­¢",
            help="SystemController æ±‡æŠ¥çš„æ•°æ®æ‘„å–çŠ¶æ€",
        )
    with col_b:
        st.metric(
            "å¾…å¤„ç†äº‹ä»¶",
            ingestion.get("pending_events", "N/A"),
            help="å½“å‰æ’é˜Ÿç­‰å¾…å¢é‡å­¦ä¹ çš„äº‹ä»¶æ•°é‡",
        )
    with col_c:
        st.metric(
            "å¢é‡å¾ªç¯",
            "è¿è¡Œä¸­" if loop_status.get("running") else "å·²åœæ­¢",
            help="åå°å¢é‡è®­ç»ƒå¾ªç¯çŠ¶æ€",
        )

    extra_cols = st.columns(3)
    with extra_cols[0]:
        st.metric(
            "æ‘„å–å¼€å§‹æ—¶é—´",
            ingestion.get("started_at", "-"),
            help="æœ€è¿‘ä¸€æ¬¡å¯åŠ¨æ‘„å–çš„æ—¶é—´æˆ³",
        )
    with extra_cols[1]:
        st.metric(
            "æœ€åäº‹ä»¶æ—¶é—´",
            ingestion.get("last_event_at", "-"),
            help="äº‹ä»¶é˜Ÿåˆ—æœ€è¿‘ä¸€æ¬¡å…¥é˜Ÿæ—¶é—´",
        )
    with extra_cols[2]:
        st.metric(
            "å¢é‡æœ€åæ‰¹",
            loop_status.get("last_batch_at", "-"),
            help="å¢é‡å­¦ä¹ æœ€è¿‘ä¸€æ¬¡æ¶ˆè´¹äº‹ä»¶çš„æ—¶é—´æˆ³",
        )

    history = status.get("history", [])
    if history:
        st.markdown("#### ğŸ“ æœ€è¿‘æ“ä½œè®°å½•")
        df = pd.DataFrame(history)
        st.dataframe(df, use_container_width=True)
    else:
        st.info("æš‚æ— å†å²æ“ä½œè®°å½•ã€‚")


st.title("ç³»ç»Ÿè¿ç»´é¢æ¿")
st.caption("æ‰‹åŠ¨æ§åˆ¶æ•°æ®æ‘„å–ã€å¢é‡å­¦ä¹ ä¸æ¨¡å‹è®­ç»ƒæµç¨‹")

health_info = _get("/health")
if health_info:
    device_mode = health_info.get("device_mode", "-")
    device_str = health_info.get("device", "-")
    mode_label = "GPU" if device_mode.lower() == "gpu" else ("CPU" if device_mode.lower() == "cpu" else device_mode)
    st.markdown(f"**è®¾å¤‡æ¨¡å¼**ï¼š{mode_label} Â· è®¾å¤‡ï¼š`{device_str}`")

status_placeholder = st.empty()
status_data = _get("/api/v1/operations/status")
if status_data:
    with status_placeholder.container():
        _render_status_panel(status_data)
else:
    st.warning("æœªèƒ½åŠ è½½ç³»ç»ŸçŠ¶æ€ï¼Œè¯·ç¨åé‡è¯•ã€‚")

if st.button("åˆ·æ–°çŠ¶æ€æ¦‚è§ˆ", type="secondary"):
    status_data = _get("/api/v1/operations/status")
    if status_data:
        with status_placeholder.container():
            _render_status_panel(status_data)

st.markdown("### âš™ï¸ ä»»åŠ¡æ§åˆ¶")
col1, col2 = st.columns(2)
with col1:
    if st.button("å¯åŠ¨æ•°æ®æ‘„å–", type="primary"):
        result = _post("/api/v1/operations/ingestion/start", spinner="æ­£åœ¨å¯åŠ¨æ•°æ®æ‘„å–...")
        if result:
            st.success(result.get("message", "æ•°æ®æ‘„å–å·²å¯åŠ¨"))
            if result.get("status"):
                st.json(result["status"])
with col2:
    if st.button("åœæ­¢æ•°æ®æ‘„å–", type="secondary"):
        result = _post("/api/v1/operations/ingestion/stop", spinner="æ­£åœ¨åœæ­¢æ•°æ®æ‘„å–...")
        if result:
            st.success(result.get("message", "æ•°æ®æ‘„å–å·²åœæ­¢"))
            if result.get("status"):
                st.json(result["status"])

col3, col4 = st.columns(2)
with col3:
    if st.button("å¯åŠ¨å¢é‡å¾ªç¯", type="primary"):
        result = _post("/api/v1/operations/incremental/start", spinner="æ­£åœ¨å¯åŠ¨å¢é‡å¾ªç¯...")
        if result:
            st.success(result.get("message", "å¢é‡å¾ªç¯å·²å¯åŠ¨"))
            if result.get("status"):
                st.json(result["status"])
with col4:
    if st.button("åœæ­¢å¢é‡å¾ªç¯", type="secondary"):
        result = _post("/api/v1/operations/incremental/stop", spinner="æ­£åœ¨åœæ­¢å¢é‡å¾ªç¯...")
        if result:
            st.success(result.get("message", "å¢é‡å¾ªç¯å·²åœæ­¢"))
            if result.get("status"):
                st.json(result["status"])

st.markdown("### ğŸ§  èåˆæ¨¡å‹è®­ç»ƒ")
with st.form("fusion_train_form"):
    sample_size = st.number_input("é‡‡æ ·ç”¨æˆ·æ•°", min_value=32, max_value=10000, value=256, step=32)
    epochs = st.number_input("è®­ç»ƒè½®æ¬¡", min_value=1, max_value=200, value=3, step=1)
    lr = st.number_input("å­¦ä¹ ç‡", min_value=1e-5, max_value=1.0, value=1e-3, step=1e-4, format="%.5f")
    batch_size = st.number_input("æ‰¹å¤§å°", min_value=8, max_value=1024, value=64, step=8)
    submitted = st.form_submit_button("å¼€å§‹è®­ç»ƒ", type="primary")
    if submitted:
        result = _post(
            "/api/v1/operations/fusion/train",
            payload={
                "sample_size": int(sample_size),
                "epochs": int(epochs),
                "lr": float(lr),
                "batch_size": int(batch_size),
            },
            spinner="èåˆæ ¸å¿ƒè®­ç»ƒè¿›è¡Œä¸­...",
        )
        if result:
            st.success(result.get("message", "è®­ç»ƒå·²å®Œæˆ"))
            st.json(result.get("metrics", result))

st.markdown("### ğŸ§¹ ç¼“å­˜ä¸è§„åˆ™ç»´æŠ¤")
col5, col6 = st.columns(2)
with col5:
    if st.button("åˆ·æ–°è§„åˆ™ç»“æ„", type="primary"):
        result = _post("/api/v1/operations/rules/refresh", spinner="æ­£åœ¨åˆ·æ–°è§„åˆ™ç»“æ„...")
        if result:
            st.success(result.get("message", "è§„åˆ™åˆ·æ–°å®Œæˆ"))
with col6:
    if st.button("æ¸…ç©ºè§£é‡Šå™¨ç¼“å­˜", type="secondary"):
        result = _post("/api/v1/operations/explainer/clear", spinner="æ­£åœ¨æ¸…ç†è§£é‡Šå™¨ç¼“å­˜...")
        if result:
            st.success(result.get("message", "è§£é‡Šå™¨ç¼“å­˜å·²æ¸…ç©º"))

st.markdown("### ğŸ›‘ åœæœºï¼ˆä»…æœ¬åœ°/å®¹å™¨è°ƒè¯•ï¼‰")
with st.form("shutdown_form"):
    st.warning("è¯¥æ“ä½œå°†æ˜¾å¼åœæ­¢åå°ä»»åŠ¡å¹¶å…³é—­åç«¯çš„å¼‚æ­¥äº‹ä»¶å¾ªç¯ï¼Œåœæœºåéœ€é‡å¯åç«¯è¿›ç¨‹ä»¥æ¢å¤æœåŠ¡ã€‚")
    confirm_shutdown = st.checkbox("æˆ‘å·²äº†è§£åœæœºå½±å“å¹¶ç¡®è®¤ç»§ç»­")
    submitted_shutdown = st.form_submit_button("æ‰§è¡Œåœæœº", type="primary")
    if submitted_shutdown:
        if not confirm_shutdown:
            st.warning("è¯·å‹¾é€‰ç¡®è®¤åå†æ‰§è¡Œåœæœºã€‚")
        else:
            result = _post("/api/v1/operations/shutdown", spinner="æ­£åœ¨åœæœº...")
            if result is not None:
                st.success(result.get("message", "åç«¯åœæœºå®Œæˆ"))
                st.info("å¦‚éœ€ç»§ç»­ä½¿ç”¨ï¼Œè¯·é‡æ–°å¯åŠ¨åç«¯æœåŠ¡ã€‚")

st.divider()
st.markdown("å¦‚éœ€æœ€æ–°çŠ¶æ€ï¼Œè¯·ä½¿ç”¨ä¾§è¾¹æ çš„é‡æ–°è¿è¡ŒæŒ‰é’®æˆ–åˆ·æ–°é¡µé¢ã€‚")
